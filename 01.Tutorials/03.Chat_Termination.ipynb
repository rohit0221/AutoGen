{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Terminating Conversations Between Agents\n",
    "\n",
    "We will explore how to terminate a conversation between AutoGen agents.\n",
    "\n",
    "\n",
    "in any complex, autonomous workflows it’s crucial to know when to stop the workflow. For example, when the task is completed, or perhaps when the process has consumed enough resources and needs to either stop or adopt different strategies, such as user intervention. So AutoGen natively supports several mechanisms to terminate conversations.\n",
    "\n",
    "Currently there are two broad mechanism to control the termination of conversations between agents:\n",
    "\n",
    "1. **Specify parameters in ```initiate_chat```**: When initiating a chat, you can define parameters that determine when the conversation should end.\n",
    "\n",
    "2. **Configure an agent to trigger termination**: When defining individual agents, you can specify parameters that allow agents to terminate of a conversation based on particular (configurable) conditions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters in ```initiate_chat```\n",
    "\n",
    "This is done by ```max_turns``` parameter ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from autogen import ConversableAgent\n",
    "\n",
    "cathy = ConversableAgent(\n",
    "    \"cathy\",\n",
    "    system_message=\"Your name is Cathy and you are a part of a duo of comedians.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"temperature\": 0.9, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")\n",
    "\n",
    "joe = ConversableAgent(\n",
    "    \"joe\",\n",
    "    system_message=\"Your name is Joe and you are a part of a duo of comedians.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"temperature\": 0.7, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Cathy, tell me a joke.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Sure, Joe! Why did the scarecrow win an award? \n",
      "\n",
      "Because he was outstanding in his field!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "That's a classic! Alright, here's one for you: Why don't skeletons fight each other? \n",
      "\n",
      "They don't have the guts!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, good one, Joe! Alright, I've got another for you: What do you call fake spaghetti? \n",
      "\n",
      "An impasta!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "result = joe.initiate_chat(cathy, message=\"Cathy, tell me a joke.\", max_turns=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent-triggered termination\n",
    "Currently, there are two parameters you can configure:\n",
    "\n",
    "1. ```max_consecutive_auto_reply```: This condition triggers termination if the number of automatic responses to the same sender exceeds a threshold. You can customize this using the ```max_consecutive_auto_reply``` argument of the ```ConversableAgent``` class. To accomplish this the agent maintains a counter of the number of consecutive automatic responses to the same sender. Note that this counter can be reset because of human intervention. We will describe this in more detail in the next chapter.\n",
    "\n",
    "2. ```is_termination_msg```: This condition can trigger termination if the received message satisfies a particular condition, e.g., it contains the word “TERMINATE”. You can customize this condition using the ```is_terminate_msg``` argument in the constructor of the ```ConversableAgent``` class."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using ```max_consecutive_auto_reply```\n",
    "\n",
    "In the example below lets set ```max_consecutive_auto_reply``` to ```1``` and notice how this ensures that Joe only replies once.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Cathy, tell me a joke.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Sure, Joe! Why did the scarecrow win an award? \n",
      "\n",
      "Because he was outstanding in his field!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "That's a classic! Alright, here's one for you: Why don't skeletons fight each other? \n",
      "\n",
      "They don't have the guts!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Haha, good one, Joe! Alright, I've got another for you: What do you call fake spaghetti? \n",
      "\n",
      "An impasta!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "joe = ConversableAgent(\n",
    "    \"joe\",\n",
    "    system_message=\"Your name is Joe and you are a part of a duo of comedians.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"temperature\": 0.7, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    "    max_consecutive_auto_reply=1,  # Limit the number of consecutive auto-replies.\n",
    ")\n",
    "\n",
    "result = joe.initiate_chat(cathy, message=\"Cathy, tell me a joke.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using ```is_termination_msg```\n",
    "\n",
    "Let’s set the termination message to “GOOD BYE” and see how the conversation terminates.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mjoe\u001b[0m (to cathy):\n",
      "\n",
      "Cathy, tell me a joke and then say the words GOOD BYE.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\u001b[33mcathy\u001b[0m (to joe):\n",
      "\n",
      "Sure! Here you go: \n",
      "\n",
      "Why did the scarecrow win an award? \n",
      "\n",
      "Because he was outstanding in his field! \n",
      "\n",
      "GOOD BYE!\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "joe = ConversableAgent(\n",
    "    \"joe\",\n",
    "    system_message=\"Your name is Joe and you are a part of a duo of comedians.\",\n",
    "    llm_config={\"config_list\": [{\"model\": \"gpt-4o-mini\", \"temperature\": 0.7, \"api_key\": os.environ.get(\"OPENAI_API_KEY\")}]},\n",
    "    human_input_mode=\"NEVER\",  # Never ask for human input.\n",
    "    is_termination_msg=lambda msg: \"good bye\" in msg[\"content\"].lower(),\n",
    ")\n",
    "\n",
    "result = joe.initiate_chat(cathy, message=\"Cathy, tell me a joke and then say the words GOOD BYE.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
